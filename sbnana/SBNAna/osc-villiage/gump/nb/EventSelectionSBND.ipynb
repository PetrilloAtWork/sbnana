{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#print all output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "# from util import *\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASS_MUON = 0.105658\n",
    "MASS_NEUTRON = 0.9395654\n",
    "MASS_PROTON = 0.938272\n",
    "MASS_A = 22*MASS_NEUTRON + 18*MASS_PROTON - 0.34381\n",
    "BE = 0.0295\n",
    "MASS_Ap = MASS_A - MASS_NEUTRON + BE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag2d(x, y):\n",
    "    return np.sqrt(x**2 + y**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast(v, df):\n",
    "    for vi, ii in zip(v.index.names, df.index.names):\n",
    "        if vi != ii:\n",
    "            raise ValueError(\"Value index (%s) does not match index (%s).\" % (str(vi), str(ii)))\n",
    "    if len(v.index.names) > len(df.index.names):\n",
    "        raise ValueError(\"Value index too long.\")\n",
    "    if len(v.index.names) == len(df.index.names):\n",
    "        return v\n",
    "\n",
    "    rpt = df.groupby(level=list(range(v.index.nlevels))).size()\n",
    "    has_value = v.index.intersection(rpt.index)\n",
    "    v_rpt = np.repeat(v.loc[has_value].values, rpt)\n",
    "\n",
    "    return pd.Series(v_rpt, df.index).rename(v.name) \n",
    "\n",
    "def multicol_concat(lhs, rhs):\n",
    "    # Fix the columns\n",
    "    lhs_col = lhs.columns\n",
    "    rhs_col = rhs.columns\n",
    "\n",
    "    nlevel = max(lhs_col.nlevels, rhs_col.nlevels)\n",
    "\n",
    "    def pad(c):\n",
    "       return tuple(list(c) + [\"\"]*(nlevel - len(c))) \n",
    "\n",
    "    lhs.columns = pd.MultiIndex.from_tuples([pad(c) for c in lhs_col])\n",
    "    rhs.columns = pd.MultiIndex.from_tuples([pad(c) for c in rhs_col])\n",
    "\n",
    "    return pd.concat([lhs, rhs], axis=1)\n",
    "\n",
    "def multicol_add(df, s, **panda_kwargs):\n",
    "    # if both the series and the df is one level, we can do a simple join()\n",
    "    if isinstance(s.name, str) and df.columns.nlevels == 1:\n",
    "        return df.join(s, **panda_kwargs)\n",
    "\n",
    "    if isinstance(s.name, str):\n",
    "        s.name = (s.name,)\n",
    "\n",
    "    nlevel = max(df.columns.nlevels, len(s.name))\n",
    "    def pad(c):\n",
    "       return tuple(list(c) + [\"\"]*(nlevel - len(c))) \n",
    "\n",
    "    if df.columns.nlevels < nlevel:\n",
    "        df.columns = pd.MultiIndex.from_tuples([pad(c) for c in df.columns])\n",
    "    if len(s.name) < nlevel:\n",
    "        s.name = pad(s.name)\n",
    "\n",
    "    return df.join(s, **panda_kwargs)\n",
    "\n",
    "def multicol_merge(lhs, rhs, **panda_kwargs):\n",
    "    # Fix the columns\n",
    "    lhs_col = lhs.columns\n",
    "    rhs_col = rhs.columns\n",
    "\n",
    "    nlevel = max(lhs_col.nlevels, rhs_col.nlevels)\n",
    "\n",
    "    def pad(c):\n",
    "       nc = 1 if isinstance(c, str) else len(c)\n",
    "       c0 = [c] if isinstance(c, str) else list(c)\n",
    "       return tuple(c0 + [\"\"]*(nlevel - nc)) \n",
    "\n",
    "    lhs.columns = pd.MultiIndex.from_tuples([pad(c) for c in lhs_col])\n",
    "    rhs.columns = pd.MultiIndex.from_tuples([pad(c) for c in rhs_col])\n",
    "\n",
    "    return lhs.merge(rhs, **panda_kwargs)\n",
    "\n",
    "def detect_vectors(tree, branch):\n",
    "    ret = []\n",
    "    hierarchy = branch.split(\".\")\n",
    "    for i in range(len(hierarchy)):\n",
    "        subbranch = \".\".join(hierarchy[:i+1])\n",
    "        lenbranch = subbranch + \"..length\"\n",
    "        if lenbranch in tree.keys():\n",
    "            ret.append(subbranch)\n",
    "    return ret\n",
    "\n",
    "def idarray(ids, lens):\n",
    "    return np.repeat(ids.values, lens.values)\n",
    "\n",
    "def loadbranches(tree, branches, **uprargs):\n",
    "    vectors = []\n",
    "    for i,branch in enumerate(branches):\n",
    "        this_vectors = detect_vectors(tree, branch)\n",
    "        if i == 0:\n",
    "            vectors = this_vectors\n",
    "        elif len(this_vectors) == 0: # This case is ok since it will automatically broadcast\n",
    "            pass\n",
    "        # All the branches must have the same vector structure for this to work\n",
    "        elif vectors != this_vectors:\n",
    "            raise ValueError(\"Branches %s and %s have different vector structures in the CAF.\" % (branches[0], branch))\n",
    "\n",
    "    lengths = [tree.arrays([v+\"..length\"], library=\"pd\", **uprargs) for v in vectors]\n",
    "    data = tree.arrays(branches, library=\"pd\", **uprargs)\n",
    "\n",
    "    # If there's no vectors, we can just return the top guy\n",
    "    if len(lengths) == 0:\n",
    "        data.index.name = \"entry\"\n",
    "        df = data\n",
    "    else:\n",
    "        tomerge = lengths + [data]\n",
    "        # Otherwise, iteratively merge the branches\n",
    "        df = tomerge[0]\n",
    "        df.index.name = \"entry\"\n",
    "\n",
    "        # handle the rest\n",
    "        for i in range(1, len(tomerge)):\n",
    "            thismerge = tomerge[i]\n",
    "            v_ind = i - 1\n",
    "\n",
    "            # Build the information in the right-hand table needed to do the join\n",
    "            # The \"upidx\" will be matched to the index vector-by-vector\n",
    "            for i in range(v_ind):\n",
    "                thismerge[vectors[v_ind] + \"..upidx\" + str(i)] = idarray(df[vectors[i]+ \"..index\"], df[vectors[v_ind] + \"..length\"])\n",
    "\n",
    "            # Inner join! Throw away rows in the right-hand with no match in the left-hand\n",
    "            df = pd.merge(df, thismerge, how=\"inner\",\n",
    "                         left_on = [\"entry\"] + [v+\"..index\" for v in vectors[:v_ind]],\n",
    "                         right_on = [\"entry\"] + [vectors[v_ind] + \"..upidx\" + str(i) for i in range(v_ind)],\n",
    "                         validate=\"one_to_many\")\n",
    "\n",
    "            # Make sure no rows in the right-hand were dropped\n",
    "            assert(df.shape[0] == thismerge.shape[0])\n",
    "\n",
    "            # postprocess: build the index\n",
    "            df[vectors[v_ind] + \"..index\"] = df.groupby([\"entry\"] + [v+\"..index\" for v in vectors[:v_ind]]).cumcount()\n",
    "\n",
    "        # Set the index\n",
    "        df.set_index([v+\"..index\" for v in vectors], append=True, verify_integrity=True, inplace=True)\n",
    "\n",
    "        # Drop all the metadata info we don't need anymore\n",
    "        df = df[branches]\n",
    "\n",
    "    # Setup branch names so df reflects structure of CAF file\n",
    "    bsplit = [b.split(\".\") for b in branches]\n",
    "    # Replace any reserved names\n",
    "    def unreserve(s):\n",
    "        if s == \"index\":\n",
    "            return \"idx\"\n",
    "        if s[0].isdigit(): # make the name a legal field \n",
    "            return \"I\" + s\n",
    "        return s\n",
    "\n",
    "    bsplit = [[unreserve(s) for s in b] for b in bsplit]\n",
    "\n",
    "    depth = max([len(b) for b in bsplit])\n",
    "\n",
    "    def pad(b):\n",
    "        return tuple(b + [\"\"]*(depth - len(b)))\n",
    "\n",
    "    df.columns = pd.MultiIndex.from_tuples([pad(b) for b in bsplit])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def issignal(df):\n",
    "    # return InFV(df.position, 50) & (df.iscc) & (df.nmu == 1) & (df.np == 1)\n",
    "    return (df.iscc) & (df.nmu == 1) & (df.np == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InFV(data): # cm\n",
    "    xmin = -199.15 + 10\n",
    "    ymin = -200. + 10\n",
    "    zmin = 0.0 + 10\n",
    "    xmax = 199.15 - 10\n",
    "    ymax =  200. - 10\n",
    "    zmax =  500. - 50\n",
    "    return (data.x > xmin) & (data.x < xmax) & (data.y > ymin) & (data.y < ymax) & (data.z > zmin) & (data.z < zmax)\n",
    "\n",
    "def InBeam(t):\n",
    "    return (t > 0.) & (t < 1.800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cosmic(df):\n",
    "    return (df.slc.truth.pdg == -1)\n",
    "\n",
    "def is_FV(df): \n",
    "    return (InFV(df.position))\n",
    "\n",
    "def is_numu(df):\n",
    "    return (np.abs(df.pdg) == 14)\n",
    "\n",
    "def is_CC(df):\n",
    "    return (df.iscc == 1)\n",
    "\n",
    "def is_NC(df):\n",
    "    return (df.iscc == 0)\n",
    "\n",
    "def is_1p0pi(df):\n",
    "    return (df.nmu_20MeV == 1) & (df.np_50MeV == 1) & (df.npi_40MeV == 0) & (df.npi0 == 0) \n",
    "\n",
    "def is_signal(df):\n",
    "    return is_numu(df) & is_CC(df) & is_1p0pi(df) & is_FV(df)\n",
    "\n",
    "def is_outFV(df):\n",
    "    return is_numu(df) & is_CC(df) & is_1p0pi(df) & np.invert(is_FV(df))\n",
    "\n",
    "def is_othernumuCC(df):\n",
    "    return is_numu(df) & is_CC(df) & np.invert(is_1p0pi(df)) & is_FV(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_list = [0, 10, 1, 2, 3]\n",
    "mode_labels = ['QE', 'MEC', 'RES', 'SIS/DIS', 'COH', \"other\"]\n",
    "mode_colors = [\"darkorchid\", \"royalblue\", \"forestgreen\", \"darkorange\", \"firebrick\"]\n",
    "\n",
    "def breakdown_mode(var, df):\n",
    "    ret = [var[df.genie_mode == i] for i in mode_list] \n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_labels = [\"Signal\",\n",
    "              \"Other numu CC\",\n",
    "              \"NC\",\n",
    "              \"Out of FV\",\n",
    "              \"Cosmic\",\n",
    "              \"Other\"]\n",
    "\n",
    "def breakdown_top(var, df):\n",
    "    ret = [var[is_signal(df)],\n",
    "           var[is_othernumuCC(df)],\n",
    "           var[is_NC(df)],\n",
    "           var[is_outFV(df)],\n",
    "           var[is_cosmic(df)],\n",
    "           var[np.invert(is_signal(df) | is_othernumuCC(df) | is_NC(df) | is_outFV(df) | is_cosmic(df))]\n",
    "           ]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make SBND eventdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"/exp/sbnd/data/users/munjung/osc/sbnd_gump.df\"\n",
    "# fname = \"/exp/sbnd/data/users/munjung/sbnd_gump.df\"\n",
    "# fname_icarus = \"/exp/sbnd/data/users/gputnam/gump.df\"\n",
    "\n",
    "with pd.HDFStore(fname) as store:\n",
    "    print(store.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcdf = pd.read_hdf(fname, \"mcnu\")\n",
    "slcdf = pd.read_hdf(fname, \"slc_trk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slcdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PID Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PID\n",
    "\n",
    "# use trackscore\n",
    "ts_cut = (slcdf.pfp.trackScore > 0.5)\n",
    "\n",
    "pid_shw = np.invert(ts_cut)\n",
    "\n",
    "# muon\n",
    "MUSEL_MUSCORE_TH = 25\n",
    "MUSEL_PSCORE_TH = 100\n",
    "MUSEL_LEN_TH = 50\n",
    "\n",
    "# TODO: use average over planes\n",
    "# muon_chi2 = (Avg(df, \"muon\", drop_0=True) < MUSEL_MUSCORE_TH) & (Avg(df, \"proton\", drop_0=True) > MUSEL_PSCORE_TH)\n",
    "\n",
    "# TODO: used BDT scores\n",
    "# len_cut = (masterdf.len.squeeze() > MUSEL_LEN_TH)\n",
    "# dazzle_muon = (masterdf.dazzle.muonScore > 0.6)\n",
    "# muon_cut = (muon_chi2) & (len_cut | dazzle_muon)\n",
    "\n",
    "mu_score_cut = (slcdf.pfp.trk.chi2pid.I2.chi2_muon < MUSEL_MUSCORE_TH) & \\\n",
    "    (slcdf.pfp.trk.chi2pid.I2.chi2_proton > MUSEL_PSCORE_TH)\n",
    "mu_len_cut = (slcdf.pfp.trk.len > MUSEL_LEN_TH)\n",
    "mu_cut = (mu_score_cut) & (mu_len_cut)\n",
    "pid_mu = (ts_cut) & (mu_cut)\n",
    "\n",
    "# proton \n",
    "PSEL_MUSCORE_TH = 0\n",
    "PSEL_PSCORE_TH = 90\n",
    "p_score_cut = (slcdf.pfp.trk.chi2pid.I2.chi2_muon > PSEL_MUSCORE_TH) & (slcdf.pfp.trk.chi2pid.I2.chi2_muon < PSEL_PSCORE_TH) \n",
    "p_cut = np.invert(mu_cut) & p_score_cut\n",
    "pid_p = (ts_cut) & (p_cut)\n",
    "\n",
    "# rest is pion\n",
    "pi_cut = np.invert(mu_cut | p_cut)\n",
    "pid_pi = (ts_cut) & (pi_cut)\n",
    "\n",
    "# TODO: don't use trackscore\n",
    "\n",
    "# ---------------------------\n",
    "\n",
    "# store PID info\n",
    "slcdf[(\"pfp\", \"pid\", \"\", \"\", \"\", \"\")] = np.nan\n",
    "slcdf.loc[pid_shw, (\"pfp\",\"pid\")] = -1\n",
    "slcdf.loc[pid_mu, (\"pfp\",\"pid\")] = 13\n",
    "slcdf.loc[pid_p, (\"pfp\",\"pid\")] = 2212\n",
    "slcdf.loc[pid_pi, (\"pfp\",\"pid\")] = 211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_mu = (slcdf.pfp.pid == 13)\n",
    "truth_mu = (np.abs(slcdf.pfp.trk.truth.p.pdg) == 13)\n",
    "\n",
    "pid_p = (slcdf.pfp.pid == 2212)\n",
    "truth_p = (np.abs(slcdf.pfp.trk.truth.p.pdg) == 2212)\n",
    "\n",
    "pid_pi = (slcdf.pfp.pid == 211)\n",
    "truth_pi = (np.abs(slcdf.pfp.trk.truth.p.pdg) == 211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = slcdf.pfp.trk.chi2pid.I2.chi2_muon\n",
    "pvar = [var[truth_mu], var[truth_p], var[truth_pi]]\n",
    "plt.hist(pvar, bins=np.linspace(0,80,101), histtype='step', \n",
    "         label=['muon', 'proton', 'pion'], density=True)\n",
    "plt.axvline(MUSEL_MUSCORE_TH, color='r', label=\"MUSEL\")\n",
    "plt.axvline(PSEL_MUSCORE_TH, color='b', label=\"PSEL\")\n",
    "plt.xlabel(\"Muon Score\")\n",
    "plt.legend()\n",
    "plt.show();\n",
    "\n",
    "var = slcdf.pfp.trk.chi2pid.I2.chi2_proton\n",
    "pvar = [var[truth_mu], var[truth_p], var[truth_pi]]\n",
    "plt.hist(pvar, bins=np.linspace(0,200,101), histtype='step', \n",
    "         label=['muon', 'proton', 'pion'], density=True)\n",
    "plt.axvline(MUSEL_PSCORE_TH, color='r', label=\"MUSEL\")\n",
    "plt.axvline(PSEL_PSCORE_TH, color='b', label=\"PSEL\")\n",
    "plt.xlabel(\"Proton Score\")\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = slcdf.pfp.trk.len\n",
    "pvar = [var[pid_mu & truth_mu], var[pid_mu & truth_p], var[pid_mu & truth_pi]]\n",
    "plt.hist(pvar, bins=np.linspace(0,400,21), histtype=\"step\",\n",
    "         label=[\"muon\", \"proton\", \"pion\"])\n",
    "\n",
    "print(\"muon selection purity {:.2f} %\".format(100*len(var[pid_mu & truth_mu])/len(var[pid_mu])))\n",
    "plt.legend()\n",
    "plt.show();\n",
    "\n",
    "var = slcdf.pfp.trk.len\n",
    "pvar = [var[truth_mu & pid_mu], var[truth_mu & pid_p], var[truth_mu & pid_pi]]\n",
    "plt.hist(pvar, bins=np.linspace(0,400,21), histtype=\"step\",\n",
    "         label=[\"muon\", \"proton\", \"pion\"])\n",
    "\n",
    "print(\"muon selection efficiency {:.2f} %\".format(100*len(var[pid_mu & truth_mu])/len(var[truth_mu])))\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slcdf[(\"pfp\", \"trk\", \"is_contained\", \"\", \"\", \"\")] = (InFV(slcdf.pfp.trk.start)) & (InFV(slcdf.pfp.trk.end))\n",
    "\n",
    "slcdf[(\"pfp\", \"trk\", \"P\", \"p_muon\", \"\", \"\")] = np.nan\n",
    "slcdf.loc[slcdf.pfp.trk.is_contained, (\"pfp\", \"trk\", \"P\", \"p_muon\", \"\", \"\")]  = slcdf.loc[(slcdf.pfp.trk.is_contained), (\"pfp\", \"trk\", \"rangeP\", \"p_muon\", \"\", \"\")]\n",
    "slcdf.loc[np.invert(slcdf.pfp.trk.is_contained), (\"pfp\", \"trk\", \"P\", \"p_muon\",\"\", \"\")] = slcdf.loc[np.invert(slcdf.pfp.trk.is_contained), (\"pfp\", \"trk\", \"mcsP\", \"fwdP_muon\", \"\", \"\")]\n",
    "\n",
    "slcdf[(\"pfp\", \"trk\", \"P\", \"p_pion\", \"\", \"\")] = np.nan\n",
    "slcdf.loc[slcdf.pfp.trk.is_contained, (\"pfp\", \"trk\", \"P\", \"p_pion\", \"\", \"\")]  = slcdf.loc[(slcdf.pfp.trk.is_contained), (\"pfp\", \"trk\", \"rangeP\", \"p_pion\", \"\", \"\")]\n",
    "slcdf.loc[np.invert(slcdf.pfp.trk.is_contained), (\"pfp\", \"trk\", \"P\", \"p_pion\", \"\", \"\")] = slcdf.loc[np.invert(slcdf.pfp.trk.is_contained), (\"pfp\", \"trk\", \"mcsP\", \"fwdP_pion\", \"\", \"\")]\n",
    "\n",
    "slcdf[(\"pfp\", \"trk\", \"P\", \"p_proton\", \"\", \"\")] = np.nan\n",
    "slcdf.loc[slcdf.pfp.trk.is_contained, (\"pfp\", \"trk\", \"P\", \"p_proton\", \"\", \"\")]  = slcdf.loc[(slcdf.pfp.trk.is_contained), (\"pfp\", \"trk\", \"rangeP\", \"p_proton\", \"\", \"\")]\n",
    "slcdf.loc[np.invert(slcdf.pfp.trk.is_contained), (\"pfp\", \"trk\", \"P\", \"p_proton\", \"\", \"\")] = slcdf.loc[np.invert(slcdf.pfp.trk.is_contained), (\"pfp\", \"trk\", \"mcsP\", \"fwdP_proton\", \"\", \"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slcdf[(\"pfp\", \"trk\", \"cos\", \"x\", \"\", \"\")] = np.nan\n",
    "slcdf[(\"pfp\", \"trk\", \"cos\", \"x\", \"\", \"\")] = (slcdf.pfp.trk.end.x-slcdf.pfp.trk.start.x)/slcdf.pfp.trk.len\n",
    "slcdf[(\"pfp\", \"trk\", \"cos\", \"y\", \"\", \"\")] = np.nan\n",
    "slcdf[(\"pfp\", \"trk\", \"cos\", \"y\", \"\", \"\")] = (slcdf.pfp.trk.end.y-slcdf.pfp.trk.start.y)/slcdf.pfp.trk.len\n",
    "slcdf[(\"pfp\", \"trk\", \"cos\", \"z\", \"\", \"\")] = np.nan\n",
    "slcdf[(\"pfp\", \"trk\", \"cos\", \"z\", \"\", \"\")] = (slcdf.pfp.trk.end.z-slcdf.pfp.trk.start.z)/slcdf.pfp.trk.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mudf = slcdf[(slcdf.pfp.pid == 13)].sort_values(slcdf.pfp.index.names[:-1] + [(\"pfp\", \"trk\", \"len\", \"\", \"\", \"\")]).groupby(level=[0,1,2]).last()\n",
    "mudf.columns = pd.MultiIndex.from_tuples([tuple([\"mu\"] + list(c)) for c in mudf.columns])\n",
    "\n",
    "pdf = slcdf[(slcdf.pfp.pid == 2212)].sort_values(slcdf.pfp.index.names[:-1] + [(\"pfp\", \"trk\", \"len\", \"\", \"\", \"\")]).groupby(level=[0,1,2]).last()\n",
    "pdf.columns = pd.MultiIndex.from_tuples([tuple([\"p\"] + list(c)) for c in pdf.columns])\n",
    "\n",
    "slcdf = multicol_merge(slcdf, mudf, left_index=True, right_index=True, how=\"left\", validate=\"one_to_one\")\n",
    "slcdf = multicol_merge(slcdf, pdf, left_index=True, right_index=True, how=\"left\", validate=\"one_to_one\")\n",
    "\n",
    "# in case we want to cut out other objects -- save the highest energy of each other particle\n",
    "lead_shw_length = slcdf.pfp.trk.len[(slcdf.pfp.pid < 0)].groupby(level=[0,1,2]).max().rename(\"lead_shw_length\")\n",
    "slcdf = multicol_add(slcdf, lead_shw_length)\n",
    "\n",
    "lead_pion_length = slcdf.pfp.trk.len[(slcdf.pfp.pid == 211)].groupby(level=[0,1,2]).max().rename(\"lead_pion_length\")\n",
    "slcdf = multicol_add(slcdf, lead_pion_length)\n",
    "\n",
    "subl_muon_length = slcdf[(slcdf.pfp.pid == 13)].sort_values(slcdf.pfp.index.names[:-1] + [(\"pfp\", \"trk\", \"len\", \"\", \"\", \"\")]).pfp.trk.len.groupby(level=[0,1,2]).nth(-2).rename(\"subl_muon_length\")\n",
    "slcdf = multicol_add(slcdf, subl_muon_length)\n",
    "\n",
    "subl_proton_length = slcdf[(slcdf.pfp.pid == 2212)].sort_values(slcdf.pfp.index.names[:-1] + [(\"pfp\", \"trk\", \"len\", \"\", \"\", \"\")]).pfp.trk.len.groupby(level=[0,1,2]).nth(-2).rename(\"subl_proton_length\")\n",
    "slcdf = multicol_add(slcdf, subl_proton_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truth Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truth match\n",
    "\n",
    "bad_tmatch = np.invert(slcdf.slc.tmatch.eff > 0.5) & (slcdf.slc.tmatch.idx >= 0)\n",
    "slcdf.loc[bad_tmatch, (\"slc\",\"tmatch\",\"idx\", \"\", \"\", \"\", \"\")] = np.nan\n",
    "\n",
    "# match # of column levels\n",
    "mcdf.columns = pd.MultiIndex.from_tuples([tuple(list(c) +[\"\", \"\", \"\", \"\"]) for c in mcdf.columns])\n",
    "\n",
    "df = pd.merge(slcdf.reset_index(), \n",
    "              mcdf.reset_index(),\n",
    "              left_on=[(\"__ntuple\", \"\", \"\",), \n",
    "                       (\"entry\", \"\", \"\",), \n",
    "                       (\"slc\", \"tmatch\", \"idx\")], \n",
    "              right_on=[(\"__ntuple\", \"\", \"\"), \n",
    "                        (\"entry\", \"\", \"\"), \n",
    "                        (\"rec.mc.nu..index\", \"\", \"\")], \n",
    "              how=\"left\"\n",
    "              ) \n",
    "\n",
    "df = df.set_index(slcdf.index.names, verify_integrity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(\"/exp/sbnd/data/users/munjung/osc/sbnd_gump_evtdf.df\", \"evtdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vertex in FV\n",
    "\n",
    "df = df[InFV(df.slc.vertex)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosmic rejection \n",
    "\n",
    "# var = [df.slc.nu_score[is_cosmic(df)],\n",
    "#        df.slc.nu_score[np.invert(is_cosmic(df))]]\n",
    "# plt.hist(var, bins=21, label=[\"Cosmic\", \"Nu\"], histtype=\"step\", density=True)\n",
    "# plt.legend()\n",
    "# plt.show();\n",
    "\n",
    "# Traditional \n",
    "# nu_score = (df.slc.nu_score > 0.5)\n",
    "# f_match = (df.slc.fmatch.score < 7.0) & (InBeam(df.slc.fmatch.time))\n",
    "# cosmic_rejection = nu_score & f_match\n",
    "\n",
    "# CRUMBS\n",
    "# crumbs = (df.slc_crumbs_result.score > 0)\n",
    "# cosmic_rejection = (crumbs)\n",
    "\n",
    "# df = df[cosmic_rejection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has one muon, one proton, no pion, no shower\n",
    "# df = df[~np.isnan(df.mu.pfp.pid) & ~np.isnan(df.p.pfp.pid) & np.isnan(df.lead_pion_length) & np.isnan(df.lead_shw_length) & np.isnan(df.subl_muon_length) & np.isnan(df.subl_proton_length)]\n",
    "\n",
    "# has one contained muon, one contained proton, no pion, no shower\n",
    "df = df[df.mu.pfp.trk.is_contained & df.p.pfp.trk.is_contained & np.isnan(df.lead_pion_length) & np.isnan(df.lead_shw_length) & np.isnan(df.subl_muon_length) & np.isnan(df.subl_proton_length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = df.mu.pfp.trk.P.p_muon\n",
    "pvar = breakdown_top(var, df)\n",
    "n, bins, _ = plt.hist(pvar, bins=np.linspace(0,2,21), stacked=True, \n",
    "                      label=top_labels)\n",
    "print(\"signal purity {:.2f} %\".format(100*n[0].sum()/n[-1].sum()))\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: save to df in makedf?\n",
    "# Caculate transverse kinematics\n",
    "\n",
    "mu_p = df.mu.pfp.trk.P.p_muon\n",
    "mu_p_x = mu_p * df.mu.pfp.trk.cos.x\n",
    "mu_p_y = mu_p * df.mu.pfp.trk.cos.y\n",
    "mu_p_z = mu_p * df.mu.pfp.trk.cos.z\n",
    "mu_phi_x = mu_p_x/mag2d(mu_p_x, mu_p_y)\n",
    "mu_phi_y = mu_p_y/mag2d(mu_p_x, mu_p_y)\n",
    "\n",
    "p_p = df.p.pfp.trk.P.p_proton\n",
    "p_p_x = p_p * df.p.pfp.trk.cos.x\n",
    "p_p_y = p_p * df.p.pfp.trk.cos.y\n",
    "p_p_z = p_p * df.p.pfp.trk.cos.z\n",
    "p_phi_x = p_p_x/mag2d(p_p_x, p_p_y)\n",
    "p_phi_y = p_p_y/mag2d(p_p_x, p_p_y)\n",
    "\n",
    "mu_Tp_x = mu_phi_y*mu_p_x - mu_phi_x*mu_p_y\n",
    "mu_Tp_y = mu_phi_x*mu_p_x - mu_phi_y*mu_p_y\n",
    "mu_Tp = mag2d(mu_Tp_x, mu_Tp_y)\n",
    "\n",
    "p_Tp_x = mu_phi_y*p_p_x - mu_phi_x*p_p_y\n",
    "p_Tp_y = mu_phi_x*p_p_x - mu_phi_y*p_p_y\n",
    "p_Tp = mag2d(p_Tp_x, p_Tp_y)\n",
    "\n",
    "del_Tp_x = mu_Tp_x + p_Tp_x\n",
    "del_Tp_y = mu_Tp_y + p_Tp_y\n",
    "del_Tp = mag2d(del_Tp_x, del_Tp_y)\n",
    "\n",
    "del_alpha = np.arccos(-(mu_Tp_x*del_Tp_x + mu_Tp_y*del_Tp_y)/(mu_Tp*del_Tp))\n",
    "del_theta = np.arccos(-(mu_Tp_x*p_Tp_x + mu_Tp_y*p_Tp_y)/(mu_Tp*p_Tp))\n",
    "\n",
    "mu_E = mag2d(mu_p, MASS_MUON)\n",
    "p_E = mag2d(p_p, MASS_PROTON)\n",
    "\n",
    "R = MASS_A + mu_p_z + p_p_z - mu_E - p_E\n",
    "del_Lp = 0.5*R - mag2d(MASS_Ap, del_Tp)**2/(2*R)\n",
    "del_p = mag2d(del_Tp, del_Lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DELP_TH = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = breakdown_mode(del_p, df)\n",
    "n, bins, _ = plt.hist(var, bins=np.linspace(0,1,21), stacked=True, \n",
    "                      label=mode_labels, color=mode_colors)\n",
    "plt.axvline(DELP_TH, color='k', linestyle=\"--\")\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = del_p\n",
    "pvar = breakdown_top(var, df)\n",
    "n, bins, _ = plt.hist(pvar, bins=np.linspace(0,1,21), stacked=True, \n",
    "                      label=top_labels)\n",
    "plt.axvline(DELP_TH, color='k', linestyle=\"--\")\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transverse momentum cut\n",
    "df = df[del_p < DELP_TH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = df.mu.pfp.trk.P.p_muon\n",
    "pvar = breakdown_top(var, df)\n",
    "n, bins, _ = plt.hist(pvar, bins=np.linspace(0,2,21), stacked=True, \n",
    "                      label=top_labels)\n",
    "print(\"signal purity {:.2f} %\".format(100*n[0].sum()/n[-1].sum()))\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
