{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#print all output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "# from util import *\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASS_MUON = 0.105658\n",
    "MASS_NEUTRON = 0.9395654\n",
    "MASS_PROTON = 0.938272\n",
    "MASS_A = 22*MASS_NEUTRON + 18*MASS_PROTON - 0.34381\n",
    "BE = 0.0295\n",
    "MASS_Ap = MASS_A - MASS_NEUTRON + BE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag2d(x, y):\n",
    "    return np.sqrt(x**2 + y**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast(v, df):\n",
    "    for vi, ii in zip(v.index.names, df.index.names):\n",
    "        if vi != ii:\n",
    "            raise ValueError(\"Value index (%s) does not match index (%s).\" % (str(vi), str(ii)))\n",
    "    if len(v.index.names) > len(df.index.names):\n",
    "        raise ValueError(\"Value index too long.\")\n",
    "    if len(v.index.names) == len(df.index.names):\n",
    "        return v\n",
    "\n",
    "    rpt = df.groupby(level=list(range(v.index.nlevels))).size()\n",
    "    has_value = v.index.intersection(rpt.index)\n",
    "    v_rpt = np.repeat(v.loc[has_value].values, rpt)\n",
    "\n",
    "    return pd.Series(v_rpt, df.index).rename(v.name) \n",
    "\n",
    "def multicol_concat(lhs, rhs):\n",
    "    # Fix the columns\n",
    "    lhs_col = lhs.columns\n",
    "    rhs_col = rhs.columns\n",
    "\n",
    "    nlevel = max(lhs_col.nlevels, rhs_col.nlevels)\n",
    "\n",
    "    def pad(c):\n",
    "       return tuple(list(c) + [\"\"]*(nlevel - len(c))) \n",
    "\n",
    "    lhs.columns = pd.MultiIndex.from_tuples([pad(c) for c in lhs_col])\n",
    "    rhs.columns = pd.MultiIndex.from_tuples([pad(c) for c in rhs_col])\n",
    "\n",
    "    return pd.concat([lhs, rhs], axis=1)\n",
    "\n",
    "def multicol_add(df, s, **panda_kwargs):\n",
    "    # if both the series and the df is one level, we can do a simple join()\n",
    "    if isinstance(s.name, str) and df.columns.nlevels == 1:\n",
    "        return df.join(s, **panda_kwargs)\n",
    "\n",
    "    if isinstance(s.name, str):\n",
    "        s.name = (s.name,)\n",
    "\n",
    "    nlevel = max(df.columns.nlevels, len(s.name))\n",
    "    def pad(c):\n",
    "       return tuple(list(c) + [\"\"]*(nlevel - len(c))) \n",
    "\n",
    "    if df.columns.nlevels < nlevel:\n",
    "        df.columns = pd.MultiIndex.from_tuples([pad(c) for c in df.columns])\n",
    "    if len(s.name) < nlevel:\n",
    "        s.name = pad(s.name)\n",
    "\n",
    "    return df.join(s, **panda_kwargs)\n",
    "\n",
    "def multicol_merge(lhs, rhs, **panda_kwargs):\n",
    "    # Fix the columns\n",
    "    lhs_col = lhs.columns\n",
    "    rhs_col = rhs.columns\n",
    "\n",
    "    nlevel = max(lhs_col.nlevels, rhs_col.nlevels)\n",
    "\n",
    "    def pad(c):\n",
    "       nc = 1 if isinstance(c, str) else len(c)\n",
    "       c0 = [c] if isinstance(c, str) else list(c)\n",
    "       return tuple(c0 + [\"\"]*(nlevel - nc)) \n",
    "\n",
    "    lhs.columns = pd.MultiIndex.from_tuples([pad(c) for c in lhs_col])\n",
    "    rhs.columns = pd.MultiIndex.from_tuples([pad(c) for c in rhs_col])\n",
    "\n",
    "    return lhs.merge(rhs, **panda_kwargs)\n",
    "\n",
    "def detect_vectors(tree, branch):\n",
    "    ret = []\n",
    "    hierarchy = branch.split(\".\")\n",
    "    for i in range(len(hierarchy)):\n",
    "        subbranch = \".\".join(hierarchy[:i+1])\n",
    "        lenbranch = subbranch + \"..length\"\n",
    "        if lenbranch in tree.keys():\n",
    "            ret.append(subbranch)\n",
    "    return ret\n",
    "\n",
    "def idarray(ids, lens):\n",
    "    return np.repeat(ids.values, lens.values)\n",
    "\n",
    "def loadbranches(tree, branches, **uprargs):\n",
    "    vectors = []\n",
    "    for i,branch in enumerate(branches):\n",
    "        this_vectors = detect_vectors(tree, branch)\n",
    "        if i == 0:\n",
    "            vectors = this_vectors\n",
    "        elif len(this_vectors) == 0: # This case is ok since it will automatically broadcast\n",
    "            pass\n",
    "        # All the branches must have the same vector structure for this to work\n",
    "        elif vectors != this_vectors:\n",
    "            raise ValueError(\"Branches %s and %s have different vector structures in the CAF.\" % (branches[0], branch))\n",
    "\n",
    "    lengths = [tree.arrays([v+\"..length\"], library=\"pd\", **uprargs) for v in vectors]\n",
    "    data = tree.arrays(branches, library=\"pd\", **uprargs)\n",
    "\n",
    "    # If there's no vectors, we can just return the top guy\n",
    "    if len(lengths) == 0:\n",
    "        data.index.name = \"entry\"\n",
    "        df = data\n",
    "    else:\n",
    "        tomerge = lengths + [data]\n",
    "        # Otherwise, iteratively merge the branches\n",
    "        df = tomerge[0]\n",
    "        df.index.name = \"entry\"\n",
    "\n",
    "        # handle the rest\n",
    "        for i in range(1, len(tomerge)):\n",
    "            thismerge = tomerge[i]\n",
    "            v_ind = i - 1\n",
    "\n",
    "            # Build the information in the right-hand table needed to do the join\n",
    "            # The \"upidx\" will be matched to the index vector-by-vector\n",
    "            for i in range(v_ind):\n",
    "                thismerge[vectors[v_ind] + \"..upidx\" + str(i)] = idarray(df[vectors[i]+ \"..index\"], df[vectors[v_ind] + \"..length\"])\n",
    "\n",
    "            # Inner join! Throw away rows in the right-hand with no match in the left-hand\n",
    "            df = pd.merge(df, thismerge, how=\"inner\",\n",
    "                         left_on = [\"entry\"] + [v+\"..index\" for v in vectors[:v_ind]],\n",
    "                         right_on = [\"entry\"] + [vectors[v_ind] + \"..upidx\" + str(i) for i in range(v_ind)],\n",
    "                         validate=\"one_to_many\")\n",
    "\n",
    "            # Make sure no rows in the right-hand were dropped\n",
    "            assert(df.shape[0] == thismerge.shape[0])\n",
    "\n",
    "            # postprocess: build the index\n",
    "            df[vectors[v_ind] + \"..index\"] = df.groupby([\"entry\"] + [v+\"..index\" for v in vectors[:v_ind]]).cumcount()\n",
    "\n",
    "        # Set the index\n",
    "        df.set_index([v+\"..index\" for v in vectors], append=True, verify_integrity=True, inplace=True)\n",
    "\n",
    "        # Drop all the metadata info we don't need anymore\n",
    "        df = df[branches]\n",
    "\n",
    "    # Setup branch names so df reflects structure of CAF file\n",
    "    bsplit = [b.split(\".\") for b in branches]\n",
    "    # Replace any reserved names\n",
    "    def unreserve(s):\n",
    "        if s == \"index\":\n",
    "            return \"idx\"\n",
    "        if s[0].isdigit(): # make the name a legal field \n",
    "            return \"I\" + s\n",
    "        return s\n",
    "\n",
    "    bsplit = [[unreserve(s) for s in b] for b in bsplit]\n",
    "\n",
    "    depth = max([len(b) for b in bsplit])\n",
    "\n",
    "    def pad(b):\n",
    "        return tuple(b + [\"\"]*(depth - len(b)))\n",
    "\n",
    "    df.columns = pd.MultiIndex.from_tuples([pad(b) for b in bsplit])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def issignal(df):\n",
    "    # return InFV(df.position, 50) & (df.iscc) & (df.nmu == 1) & (df.np == 1)\n",
    "    return (df.iscc) & (df.nmu == 1) & (df.np == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InFV(data): # cm\n",
    "    xmin = -199.15 + 10\n",
    "    ymin = -200. + 10\n",
    "    zmin = 0.0 + 10\n",
    "    xmax = 199.15 - 10\n",
    "    ymax =  200. - 10\n",
    "    zmax =  500. - 50\n",
    "    return (data.x > xmin) & (data.x < xmax) & (data.y > ymin) & (data.y < ymax) & (data.z > zmin) & (data.z < zmax)\n",
    "\n",
    "def InBeam(t):\n",
    "    return (t > 0.) & (t < 1.800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cosmic(df):\n",
    "    return (df.slc.truth.pdg == -1)\n",
    "\n",
    "def is_FV(df): \n",
    "    return (InFV(df.position))\n",
    "\n",
    "def is_numu(df):\n",
    "    return (np.abs(df.pdg) == 14)\n",
    "\n",
    "def is_CC(df):\n",
    "    return (df.iscc == 1)\n",
    "\n",
    "def is_NC(df):\n",
    "    return (df.iscc == 0)\n",
    "\n",
    "def is_1p0pi(df):\n",
    "    return (df.nmu_20MeV == 1) & (df.np_50MeV == 1) & (df.npi_40MeV == 0) & (df.npi0 == 0) \n",
    "\n",
    "def is_signal(df):\n",
    "    return is_numu(df) & is_CC(df) & is_1p0pi(df) & is_FV(df)\n",
    "\n",
    "def is_outFV(df):\n",
    "    return is_numu(df) & is_CC(df) & is_1p0pi(df) & np.invert(is_FV(df))\n",
    "\n",
    "def is_othernumuCC(df):\n",
    "    return is_numu(df) & is_CC(df) & np.invert(is_1p0pi(df)) & is_FV(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_list = [0, 10, 1, 2, 3]\n",
    "mode_labels = ['QE', 'MEC', 'RES', 'SIS/DIS', 'COH', \"other\"]\n",
    "mode_colors = [\"darkorchid\", \"royalblue\", \"forestgreen\", \"darkorange\", \"firebrick\"]\n",
    "\n",
    "def breakdown_mode(var, df):\n",
    "    ret = [var[df.genie_mode == i] for i in mode_list] \n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_labels = [\"Signal\",\n",
    "              \"Other numu CC\",\n",
    "              \"NC\",\n",
    "              \"Out of FV\",\n",
    "              \"Cosmic\",\n",
    "              \"Other\"]\n",
    "\n",
    "def breakdown_top(var, df):\n",
    "    ret = [var[is_signal(df)],\n",
    "           var[is_othernumuCC(df)],\n",
    "           var[is_NC(df)],\n",
    "           var[is_outFV(df)],\n",
    "           var[is_cosmic(df)],\n",
    "           var[np.invert(is_signal(df) | is_othernumuCC(df) | is_NC(df) | is_outFV(df) | is_cosmic(df))]\n",
    "           ]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(\"/exp/sbnd/data/users/munjung/osc/sbnd_gump.df\", \"evt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vertex in FV\n",
    "\n",
    "df = df[InFV(df.slc.vertex)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosmic rejection \n",
    "\n",
    "# var = [df.slc.nu_score[is_cosmic(df)],\n",
    "#        df.slc.nu_score[np.invert(is_cosmic(df))]]\n",
    "# plt.hist(var, bins=21, label=[\"Cosmic\", \"Nu\"], histtype=\"step\", density=True)\n",
    "# plt.legend()\n",
    "# plt.show();\n",
    "\n",
    "# Traditional \n",
    "nu_score = (df.slc.nu_score > 0.5)\n",
    "# f_match = (df.slc.fmatch.score < 7.0) & (InBeam(df.slc.fmatch.time))\n",
    "cosmic_rejection = nu_score #& f_match\n",
    "\n",
    "# CRUMBS\n",
    "# crumbs = (df.slc_crumbs_result.score > 0)\n",
    "# cosmic_rejection = (crumbs)\n",
    "\n",
    "df = df[cosmic_rejection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has one muon, one proton, no pion, no shower\n",
    "# df = df[~np.isnan(df.mu.pfp.pid) & ~np.isnan(df.p.pfp.pid) & np.isnan(df.lead_pion_length) & np.isnan(df.lead_shw_length) & np.isnan(df.subl_muon_length) & np.isnan(df.subl_proton_length)]\n",
    "\n",
    "# has one contained muon, one contained proton, no pion, no shower\n",
    "df = df[df.mu.pfp.trk.is_contained & df.p.pfp.trk.is_contained & np.isnan(df.lead_pion_length) & np.isnan(df.lead_shw_length) & np.isnan(df.subl_muon_length) & np.isnan(df.subl_proton_length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = df.mu.pfp.trk.P.p_muon\n",
    "pvar = breakdown_top(var, df)\n",
    "n, bins, _ = plt.hist(pvar, bins=np.linspace(0,2,21), stacked=True, \n",
    "                      label=top_labels)\n",
    "print(\"signal purity {:.2f} %\".format(100*n[0].sum()/n[-1].sum()))\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no stub\n",
    "df = df[np.invert(df.slc.has_stub)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = df.mu.pfp.trk.P.p_muon\n",
    "pvar = breakdown_top(var, df)\n",
    "n, bins, _ = plt.hist(pvar, bins=np.linspace(0,2,21), stacked=True, \n",
    "                      label=top_labels)\n",
    "print(\"signal purity {:.2f} %\".format(100*n[0].sum()/n[-1].sum()))\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: save to df in makedf?\n",
    "# Caculate transverse kinematics\n",
    "\n",
    "mu_p = df.mu.pfp.trk.P.p_muon\n",
    "mu_p_x = mu_p * df.mu.pfp.trk.cos.x\n",
    "mu_p_y = mu_p * df.mu.pfp.trk.cos.y\n",
    "mu_p_z = mu_p * df.mu.pfp.trk.cos.z\n",
    "mu_phi_x = mu_p_x/mag2d(mu_p_x, mu_p_y)\n",
    "mu_phi_y = mu_p_y/mag2d(mu_p_x, mu_p_y)\n",
    "\n",
    "p_p = df.p.pfp.trk.P.p_proton\n",
    "p_p_x = p_p * df.p.pfp.trk.cos.x\n",
    "p_p_y = p_p * df.p.pfp.trk.cos.y\n",
    "p_p_z = p_p * df.p.pfp.trk.cos.z\n",
    "p_phi_x = p_p_x/mag2d(p_p_x, p_p_y)\n",
    "p_phi_y = p_p_y/mag2d(p_p_x, p_p_y)\n",
    "\n",
    "mu_Tp_x = mu_phi_y*mu_p_x - mu_phi_x*mu_p_y\n",
    "mu_Tp_y = mu_phi_x*mu_p_x - mu_phi_y*mu_p_y\n",
    "mu_Tp = mag2d(mu_Tp_x, mu_Tp_y)\n",
    "\n",
    "p_Tp_x = mu_phi_y*p_p_x - mu_phi_x*p_p_y\n",
    "p_Tp_y = mu_phi_x*p_p_x - mu_phi_y*p_p_y\n",
    "p_Tp = mag2d(p_Tp_x, p_Tp_y)\n",
    "\n",
    "del_Tp_x = mu_Tp_x + p_Tp_x\n",
    "del_Tp_y = mu_Tp_y + p_Tp_y\n",
    "del_Tp = mag2d(del_Tp_x, del_Tp_y)\n",
    "\n",
    "del_alpha = np.arccos(-(mu_Tp_x*del_Tp_x + mu_Tp_y*del_Tp_y)/(mu_Tp*del_Tp))\n",
    "del_theta = np.arccos(-(mu_Tp_x*p_Tp_x + mu_Tp_y*p_Tp_y)/(mu_Tp*p_Tp))\n",
    "\n",
    "mu_E = mag2d(mu_p, MASS_MUON)\n",
    "p_E = mag2d(p_p, MASS_PROTON)\n",
    "\n",
    "R = MASS_A + mu_p_z + p_p_z - mu_E - p_E\n",
    "del_Lp = 0.5*R - mag2d(MASS_Ap, del_Tp)**2/(2*R)\n",
    "del_p = mag2d(del_Tp, del_Lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DELP_TH = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = breakdown_mode(del_p, df)\n",
    "n, bins, _ = plt.hist(var, bins=np.linspace(0,1,21), stacked=True, \n",
    "                      label=mode_labels, color=mode_colors)\n",
    "plt.axvline(DELP_TH, color='k', linestyle=\"--\")\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = del_p\n",
    "pvar = breakdown_top(var, df)\n",
    "n, bins, _ = plt.hist(pvar, bins=np.linspace(0,1,21), stacked=True, \n",
    "                      label=top_labels)\n",
    "plt.axvline(DELP_TH, color='k', linestyle=\"--\")\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transverse momentum cut\n",
    "df = df[del_p < DELP_TH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = df.mu.pfp.trk.P.p_muon\n",
    "pvar = breakdown_top(var, df)\n",
    "n, bins, _ = plt.hist(pvar, bins=np.linspace(0,2,21), stacked=True, \n",
    "                      label=top_labels)\n",
    "print(\"signal purity {:.2f} %\".format(100*n[0].sum()/n[-1].sum()))\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3 (.conda-env)",
   "language": "python",
   "name": "conda-env-.conda-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
